<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
<TITLE>Programmation multitâches
LinuxThreads </TITLE>
<META NAME="description" CONTENT="Programmation multitâches
LinuxThreads ">
<META NAME="keywords" CONTENT="threads">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v2K.1beta">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="threads.css">

</HEAD>
<BODY >
<P>
<H1 ALIGN="CENTER">Programmation multitâches
<BR>
LinuxThreads </H1>

<DIV ALIGN="CENTER"><IMG
 ALIGN="BOTTOM" BORDER="0"
 SRC="/images/logo_labo.jpg"
 ALT="Laboratoire Unix - Supinfo Paris"> </DIV>
<P ALIGN="CENTER"><STRONG>Julien GATEAUD - Labo-Unix - http://www.labo-unix.net
</STRONG></P>
<P ALIGN="CENTER"><STRONG>2001-2002</STRONG></P>
<H2><A NAME="SECTION00010000000000000000">
Contents</A>
</H2>
<!--Table of Contents-->

<UL>
<LI><A NAME="tex2html15"
  HREF="threads.html">Introduction</A>
<LI><A NAME="tex2html16"
  HREF="#SECTION00030000000000000000">1 Un peu de théorie ...</A>
<UL>
<LI><A NAME="tex2html17"
  HREF="#SECTION00031000000000000000">1.1 Qu'est-ce qu'un thread ?</A>
<LI><A NAME="tex2html18"
  HREF="#SECTION00032000000000000000">1.2 Atomicité</A>
<LI><A NAME="tex2html19"
  HREF="#SECTION00033000000000000000">1.3 Volatilité</A>
<LI><A NAME="tex2html20"
  HREF="#SECTION00034000000000000000">1.4 Verrous</A>
</UL>
<BR>
<LI><A NAME="tex2html21"
  HREF="#SECTION00040000000000000000">2 LinuxThreads en pratique ...</A>
<UL>
<LI><A NAME="tex2html22"
  HREF="#SECTION00041000000000000000">2.1 Un premier programme</A>
<LI><A NAME="tex2html23"
  HREF="#SECTION00042000000000000000">2.2 Gestion des données partagées</A>
</UL>
<BR>
<!--End of Table of Contents-->

<P>

<P>

<H1><A NAME="SECTION00020000000000000000">
Introduction</A>
</H1>

<P>
Ce document présente la bibliothèque de développement <I>LinuxThreads</I>
crée par Xavier Leroy. C' est une implémentation gratuite de
la norme POSIX 1003.1c qui est censée assurer une certaine portabilité
entre les différents systèmes d'exploitation. POSIX 1003.1c n'est
malheureusement pas toujours supportée par les OS; si Solaris y est
totalement conforme, on ne peut pas en dire autant d'autres OS même
s'il existe des projets visant à ajouter cette compatibilité (on peut
remarquer notamment le projet Open Source Pthreads-Win32 qui apporte
(enfin) un réel support de la norme dans Windows). <I>LinuxThread</I>
est presque entièrement conforme, les seuls différences qu'on peut
trouver résident dans le nomage des fonctions et dans la gestion des
signaux. 

<P>
Même si nous étudions ici une seule bibliothèque, l'ensemble des notions
et des techniques de programmation des <I>threads</I> que nous verrons
pourra vous servir sur n'importe quel système d'exploitation. 

<P>
Cette méthode moderne de programmer est de nos jours la plus répandue
et la plus pratique pour développer des applications rapides et complexes.

<P>

<H1><A NAME="SECTION00030000000000000000">
1 Un peu de théorie ...</A>
</H1>

<P>
Avant de commencer l'étude des <I>LinuxThreads</I> nous allons expliquer
le principe des <I>threads</I> et des notions qui y sont associées.

<P>

<H2><A NAME="SECTION00031000000000000000">
1.1 Qu'est-ce qu'un thread ?</A>
</H2>

<P>
Un <I>thread</I> peut être considéré comme une forme de mini-processus.
Plusieurs mini-processus peuvent s'executer en parallèle avec d'autres
dans un même programme. Les programmes utilisant les <I>threads</I>
permettent, tout comme les programmes multi-processus, d'échapper
à l' exécution séquentielle des instructions et ainsi de pouvoir accomplir
plusieurs tâches à la fois. Mais il ne faut pas confondre avec la
programmation multi-processus classique utilisant l'appel <I>fork</I>().
Les <I>threads</I> eux, partagent tous le même espace en mémoire ainsi
que les mêmes ressources (descripteurs de fichier, sockets etc...)
contrairement aux processus classiques qui possèdent chacun leur propre
espace mémoire. Plus besoin donc d'avoir recours à un segment de mémoire
partagée pour échanger des données, chaque <I>thread</I> peut accéder
à toutes les variables d'un programme. Ceci implique aussi que le
changement de contexte entre deux <I>threads</I> est beaucoup moins
gourmand en ressources que le changement de contexte entre deux processus.
Un autre avantage des <I>threads</I> dans le cas la programmation
sur des systèmes multi-processeurs, est l'exécution en parallèle de
ceux-ci sur chacun des processeur qui permet d'exploiter au mieux
ces systèmes.

<P>

<H2><A NAME="SECTION00032000000000000000">
1.2 Atomicité</A>
</H2>

<P>
On va s'apercevoir rapidement le partage des variables entre les <I>threads</I>
comporte aussi des risques qu'il faut prendre en compte si on ne veut
assurer une certaine stabilité a nos programmes. 
<BR>
Les opérations atomiques sont des instructions (assembleur par exemple)
transparentes ne pouvant être interrompues. 
<BR>
Les opérations sur les données en C ne sont pas forcément atomiques
et cela va poser problème avec la mémoire partagée. Par exemple, une
opération d'addition <I>a+=1</I> est composé de plusieurs instructions
assembleur, une addition et une affectation. Entre ces deux instructions,
un autre <I>thread</I> peut accéder à la donnée et la modifier, provoquant
ainsi un résultat inattendu pour l'opération.

<P>

<H2><A NAME="SECTION00033000000000000000">
1.3 Volatilité</A>
</H2>

<P>
GCC va créer un problème qui s'ajoute à celui de la non-atomicité
des opérations ... 
<BR>
Il effectue des optimisations en plaçant temporairement les valeurs
de variables partagées dans les registres du processeur pour effectuer
des calculs. Les <I>threads</I> accédant à la variable à cet instant
ne peuvent pas se rendre compte des changements effectués sur celle-ci
car sa copie en mémoire n'a pas encore été modifiée. Pour lui éviter
d'effectuer ces optimisations, il faut ajouter le qualificatif <I>volatile</I>
à la déclaration de tous les objets qui seront en mémoire partagée. 

<P>

<H2><A NAME="SECTION00034000000000000000">
1.4 Verrous</A>
</H2>

<P>
On a vu que le problème de non-atomicité des opérations pose un problème
lors d'un accès concurrent à une variable. Pour éviter ce problème,
il faut pouvoir rendre atomiques les opérations sur les variables
partagées. Pour cela ont étés mis en place des systèmes de verrous
qui bloquent l'accès à une variable (a une ressource) tant que l'opération
sur celle-ci n'est pas achevée. Le principe est dès plus simple. Lorsqu'on
souhaite modifier une variable :

<P>
<DL>
<DT><STRONG>-</STRONG></DT>
<DD>on pose un verrou sur celle-ci (les autres <I>threads</I> ne peuvent
plus y accéder).
</DD>
<DT><STRONG>-</STRONG></DT>
<DD>on effectue toutes les opérations qu'on souhaite dessus (une ou
plusieurs).
</DD>
<DT><STRONG>-</STRONG></DT>
<DD>on retire le verrou (et la variable est de nouveau disponible pour
les autres <I>threads</I>).
</DD>
</DL>
Quand un verrou est déjà posé sur une variable et qu'un <I>thread</I>
souhaite y accéder, celui-ci pourra être bloqué tant que le verrou
ne sera pas retiré.

<P>

<H1><A NAME="SECTION00040000000000000000">
2 LinuxThreads en pratique ...</A>
</H1>

<P>

<H2><A NAME="SECTION00041000000000000000">
2.1 Un premier programme</A>
</H2>

<P>
Les fonctions de manipulation de <I>threads</I> sont déclarées dans
le fichier entête <I>pthread.h</I>. Nous allons étudier un premier
programme utilisant deux <I>threads</I> d'affichage qui effectuent
chacun la même opération en parallèle (afficher la valeur d'un compteur).

<P>
thread1.c :

<P>
<BR>
<PRE>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt; 


void *fonction_thread (void * arg)
{
   int i;   
   for (i = 0 ; i &lt; 5 ; i++) {
      printf ("%s thread: %d\n", (char*)arg, i);
      usleep(10);
   }
   pthread_exit(0);
} 

int main (void) {
   
   pthread_t th1, th2;
   void *ret;   
   
   if (pthread_create (&amp;th1, NULL, fonction_thread, "Premier") &lt; 0) {
      perror("premier (pthread_create)");
      exit (-1);
   }   
   if (pthread_create (&amp;th2, NULL, fonction_thread, "Second") &lt; 0) {
      perror("second (pthread_create)");
      exit (-1);
   }   
   (void)pthread_join (th1, &amp;ret);
   (void)pthread_join (th2, &amp;ret);
   
   return 0;
}
</PRE>
<P>
On le compile en utilisant la commande suivante :

<P>

<DL COMPACT>
<DT>
<DD>gcc&nbsp;-D_REENTRANT&nbsp;thread1.c&nbsp;-lpthread

<P>
</DD>
</DL>Dans ce programme simple, on utilise trois fonctions de <I>linuxThreads</I>
:

<P>
<DL>
<DT><STRONG>pthread_create()</STRONG></DT>
<DD>- Cette fonction permet de créer et d'associer
un <I>thread</I> à une fonction. Ici c'est la fonction d'affichage
<I>fonction_thread()</I> qu'on a associé à chacun des <I>threads</I>
. On peut aussi passer un argument de type <I>void *</I> (n'importe
quel type) à la fonction 'threadée'.
</DD>
<DT><STRONG>pthread_join()</STRONG></DT>
<DD>- sert à un <I>thread</I> ou au programme principal
à attendre la fin d'un <I>thread</I>. Le second argument de la fonction
sera remplis avec la valeur de retour du <I>thread</I>.
</DD>
<DT><STRONG>pthread_exit()</STRONG></DT>
<DD>- permet de terminer l'exécution d'un <I>thread</I>
et envoie une valeur de retour.
</DD>
</DL>
La fonction <I>sleep()</I> permet de mettre en évidence l'exécution
parallèle des deux <I>threads</I>. Sinon, le premier <I>thread</I>
aurait le temps de se terminer avant même que le second ne soit crée
...

<P>

<H2><A NAME="SECTION00042000000000000000">
2.2 Gestion des données partagées</A>
</H2>

<P>
On a vu précédemment que les données partagées devaient être protégées
lorsqu'on y accédait afin d'éviter le problème de non-atomicité des
opérations. La méthode la plus simple pour placer un verrou et ainsi
protéger une donnée s'appelle <I>Mutex</I>.

<P>

<H3><A NAME="SECTION00042100000000000000">
2.2.1 Les Mutex</A>
</H3>

<P>
<I>Mutex</I> vient de <I>MUTual EXclusion</I>. Leur gestion est des
des plus simple puisqu'elle consiste à utiliser deux fonctions : 

<P>
<DL>
<DT><STRONG>pthread_mutex_lock()</STRONG></DT>
<DD>- Pour placer le verrou.
</DD>
<DT><STRONG>pthread_mutex_unlock()</STRONG></DT>
<DD>- Pour le retirer.
</DD>
</DL>
Pour illustrer l'utilité des <I>Mutex</I> nous allons imaginer un
programme construit comme suit :

<P>
<DL>
<DT><STRONG>-</STRONG></DT>
<DD>un premier <I>thread</I> va remplir un tableau avec une fonction
très lente qui met une demi-seconde pour remplir une seule case (nous
simulons une fonction complexe qui effectue de nombreux calculs pour
obtenir les valeurs qu'elle met dans les cases).
</DD>
<DT><STRONG>-</STRONG></DT>
<DD>un second <I>thread</I> va lire le contenu du tableau
avec une fonction très rapide qui lit l'intégralité
du tableau en moins d'une demi-seconde.
</DD>
</DL>
Sans utiliser de <I>Mutex</I>, le programme ressemblerait à ceci :

<P>
<BR>
<PRE>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt; 


volatile int tab[5]; // Variable partagée

void *lire (void * arg)
{
   int i;
   
   for (i = 0 ; i != 5 ; i++)
     printf ("Thread lecture: tab[%d] vaut %d\n", i, tab[i]);
   pthread_exit (0);
} 

void *ecrire (void * arg)
{
   int i;
   
   for (i = 0 ; i != 5 ; i++) {
      tab[i] = 2 * i;
      printf ("Thread ecriture: tab[%d] vaut %d\n", i, tab[i]);
      usleep(500000); /* Simule un calcul complexe... */
   }
   pthread_exit (0);
} 

int main(void) {
   
   pthread_t th1, th2;
   void *ret;   
   
   if (pthread_create (&amp;th1, NULL, ecrire, NULL) &lt; 0) {
      perror("Thread ecrire (pthread_create)");
      exit (-1);
   }   
   if (pthread_create (&amp;th2, NULL, lire, NULL) &lt; 0) {
      perror("Thread lire (pthread_create)");
      exit (-1);
   }   
   (void)pthread_join (th1, &amp;ret);
   (void)pthread_join (th2, &amp;ret);
}
</PRE>
<P>
Et sa sortie ressemblerait à ceci :

<P>

<DL COMPACT>
<DT>
<DD>root@TAVARUA&nbsp;{}-&gt;./a.out&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;(1:04:24)&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[0]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[0]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[1]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[2]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[3]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[4]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[1]&nbsp;vaut&nbsp;2&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[2]&nbsp;vaut&nbsp;4&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[3]&nbsp;vaut&nbsp;6&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[4]&nbsp;vaut&nbsp;8
</DD>
</DL>Le <I>thread</I> de lecture lit donc toutes le cases avant que le
<I>thread</I> d'écriture n'ait le temps d'écrire dans toutes les cases
... C'est assez génant.

<P>
Voyons maintenant le même programme utilisant un <I>Mutex</I> pour
gérer ceci :

<P>
<BR>
<PRE>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt; 


volatile int tab[5]; // Variable partagée
pthread_mutex_t mutex;

void *lire (void * arg)
{
   int i;
//   pthread_mutex_lock(&amp;mutex);   
   for (i = 0 ; i != 5 ; i++)
     printf ("Thread lecture: tab[%d] vaut %d\n", i, tab[i]);
//   pthread_mutex_unlock(&amp;mutex);
   pthread_exit (0);
} 

void *ecrire (void * arg)
{
   int i;
   pthread_mutex_lock(&amp;mutex);   
   for (i = 0 ; i != 5 ; i++) {
      tab[i] = 2 * i;
      printf ("Thread ecriture: tab[%d] vaut %d\n", i, tab[i]);
      usleep(500000); /* Simule un calcul complexe... */
   }
   pthread_mutex_unlock(&amp;mutex);
   pthread_exit (0);
} 

int main(void) {
   
   pthread_t th1, th2;
   void *ret;   
   pthread_mutex_init(&amp;mutex, NULL);
   if (pthread_create (&amp;th1, NULL, ecrire, NULL) &lt; 0) {
      perror("Thread ecrire (pthread_create)");
      exit (-1);
   }   
   if (pthread_create (&amp;th2, NULL, lire, NULL) &lt; 0) {
      perror("Thread lire (pthread_create)");
      exit (-1);
   }   
   (void)pthread_join (th1, &amp;ret);
   (void)pthread_join (th2, &amp;ret);
}
</PRE>
<P>
Désormais sa sortie est :

<P>

<DL COMPACT>
<DT>
<DD>root@TAVARUA&nbsp;{}-&gt;./a.out&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;(1:12:55)&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[0]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[1]&nbsp;vaut&nbsp;2&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[2]&nbsp;vaut&nbsp;4&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[3]&nbsp;vaut&nbsp;6&nbsp;

<P>
Thread&nbsp;ecriture:&nbsp;tab[4]&nbsp;vaut&nbsp;8&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[0]&nbsp;vaut&nbsp;0&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[1]&nbsp;vaut&nbsp;2&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[2]&nbsp;vaut&nbsp;4&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[3]&nbsp;vaut&nbsp;6&nbsp;

<P>
Thread&nbsp;lecture:&nbsp;tab[4]&nbsp;vaut&nbsp;8
</DD>
</DL>Lorsqu'un <I>thread</I> tente de placer un verrou sur un <I>mutex</I>,
si celui-ci est déjà placé, le <I>thread</I> se bloque jusqu'a ce
qu'il puisse le placer à son tour. Dans notre exemple, le premier
<I>thread</I> à être lancé est celui qui écrit dans le le tableau,
c'est donc lui qui place en premier le verrou et le second <I>thread</I>
se retrouve bloqué lorsqu'il essaye de placer le verrou.

<P>
Les Mutex sont bien pratiques mais ils permettent juste de bloquer
des <I>threads</I> en attendant une ressource, ils n'est pas possible
de spécifier l'ordre dans lequel plusieurs <I>threads</I> peuvent
accéder à celle-ci. Pour cela nous avons les fameux sémaphores ...

<P>

<H3><A NAME="SECTION00042200000000000000">
2.2.2 Les sémaphores POSIX</A>
</H3>

<P>
Vous vous souvenez des sémaphores System V qu'on avait brièvement
présenté dans le cours IPC ? J'avais dit un truc du style : ``les
sémaphores <I>System V</I> c'est pourrit donc on va pas se faire [bip]
avec trop longtemps'' - enfin à peu près. Ca veut pas dire que le
principe des sémaphore est mauvais, mais leur gestion à la norme <I>System</I>
<I>V</I> est plus lente et gourmande en ressources que la version
<I>POSIX</I> implémenté dans <I>LinuxThreads</I>. Les sémaphores sont
purement et simplement des compteurs pour des ressources partagées
par plusieurs <I>threads</I>. Le principe appliqué à la vie courante
serait un grand magasin avec de nombreux clients et plusieurs caisses
pour payer. Le nombre de caisses libres représente le compteur du
sémaphore et les clients voulant payer représentent les <I>thread</I>
souhaitant accéder à une ressource. Le compteur de sémaphore est positif
temps qu'il reste des caisses libres et lorsqu'il est égal à 0, le
client voulant payer doit attendre qu'une caisse se libère.

<P>
Pour accéder aux fonctions sur les sémaphores, il faut utiliser le
fichier entête <I>sémaphore.h</I> en plus de <I>pthread.h</I>.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;sem_init(sem_t&nbsp;*sem,&nbsp;int&nbsp;pshared,&nbsp;unsigned&nbsp;int&nbsp;valeur);
</DD>
</DL>Initialise le sémaphore pointé par <I>sem</I>. Le compteur associé
au sémaphore est initialisé à <I>valeur</I>. L'argument <I>pshared</I>
indique si le sémaphore est local au processus courant (vaut 0) ou
s'il est partagé entre les plusieurs processus (ce dernier comportement
n'est pas encore géré par <I>LinuxThreads</I>).

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;sem_wait(sem_t&nbsp;*sem);
</DD>
</DL>Suspend le <I>thread</I> appelant la fonction jusqu'a ce que le sémaphore
pointé par <I>sem</I> ait une valeur non nulle. Lorsque le compteur
devient non nul, le compteur du sémaphore est atomiquement décrémenté.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;sem_trywait(sem_t&nbsp;*sem);
</DD>
</DL>C'est une variante non bloquante de <I>sem_wait()</I>. Si le sémaphore
pointé par <I>sem</I> est non nul, le compteur est décrémenté atomiquement
et la la fonction retourne 0. Si le compteur du sémaphore est à 0,
la fonction retourne EAGAIN.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;sem_post(sem_t&nbsp;*sem);
</DD>
</DL>Incrémente atomiquement le compteur du sémaphore pointé par <I>sem</I>.
Cette fonction n'est pas bloquante.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;sem_getvaleur(sen_t&nbsp;*sem,&nbsp;int&nbsp;*sval);
</DD>
</DL>Sauvegarde dans la variable pointée par <I>sval</I> la valeur courante
du compteur du sémaphore <I>sem</I>.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;sem_destroy(sem_t&nbsp;*sem);
</DD>
</DL>Détruit un sémaphore et libère toutes les ressources qu'il possède.
Dans <I>LinuxThreads</I> on ne peut pas associer de ressource à un
sémaphore donc cette fonction ne fait que vérifier qu'aucun <I>thread</I>
n'est bloqué sur le sémaphore.

<P>

<H3><A NAME="SECTION00042300000000000000">
2.2.3 Variables de condition</A>
</H3>

<P>
Les <I>condition variables (condvar)</I> permettent de réveiller un
<I>thread</I> endormis en fonction de la valeur d'une variable. Par
exemple, en reprenant le cas du magasin, on pourrait souhaiter qu'a
une certaine heure, les caisses ferment et que les clients ne puissent
plus payer. On pourrait gérer ceci uniquement avec des sémaphores
mais les <I>condvar</I> vont nous faciliter la tache. 

<P>
Attention ! Il faut toujours protéger la variables d'un <I>condvar</I>
avec un <I>mutex</I> pour éviter les 'race conditions'. Une 'race
condition' est le cas ou un <I>thread</I> se prépare à attendre une
condition et un autre signale la condition juste avant que le premier
n'attende réellement. Car dans ce cas, le <I>thread</I> qui se met
en attente pourrait ne jamais être réveillé.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;pthread_cond_init(pthread_cond_t&nbsp;*cond,&nbsp;pthread_cond_attr_t&nbsp;*cond_attr);
</DD>
</DL>Initialise une la <I>condvar cond</I> en utilisant les attributs de
condition spécifiés par <I>cond_attr</I> ou les attributs par défaut
si <I>cond_attr</I> vaut NULL. <I>cond_attr</I> est pour l'instant
ignoré dans l'implémentation LinuxThreads.

<P>
Plus simplement, on peut initialiser les variables de type <I>pthread_cond_t</I>
en utilisant la constante <I>PTHREAD_COND_INITIALIZER</I>.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;pthread_cond_signal(pthread_cond_t&nbsp;*cond);
</DD>
</DL>Permet de relancer un <I>thread</I> attendant la condition <I>cond</I>.
S'il aucun <I>thread</I> n'attend, il ne se passe rien, si plusieurs
threads attendent sur la même condition, un seul d'entre eux est réveillé
mais il est impossible de prédire lequel.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;pthread_cond_broadcast(pthread_cond_t&nbsp;*cond);
</DD>
</DL>Relance tous les <I>threads</I> qui attendent la condition <I>cond</I>.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;pthread_cond_wait(pthread_cond_t&nbsp;*cond,&nbsp;pthread_mutex_t&nbsp;*mutex);
</DD>
</DL>Déverrouille le mutex et attend que la variable <I>cond</I> soit signalée.
Le <I>thread</I> est endormis pendant ce temps. Le mutex doit être
préalablement verrouillé par le <I>thread</I> . Lorsque la fonction
rend la main, elle reverrouille le mutex.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;pthread_cond_timewait(pthread_cond_t&nbsp;*cond,&nbsp;pthread_mutex_t&nbsp;*mutex,&nbsp;const&nbsp;struc&nbsp;timespec&nbsp;*abstime);
</DD>
</DL>Le comportement est le même que pour la fonction précédente mais elle
s'effectue sur un laps de temps donné.

<P>

<DL COMPACT>
<DT>
<DD>int&nbsp;pthread_cond_destroy(pthread_cond_t&nbsp;*cond);
</DD>
</DL>Détruit une variable de condition. Sous Linux, cette fonction ne fait
que vérifier qu'aucun <I>thread</I> n'attend la condition.

<P>

<H5><A NAME="SECTION00042301000000000000">
2.2.3.0.1 Note sur la gestion des signaux asynchrones :</A>
</H5>

<P>
Il ne faut pas utiliser ces fonction dans un 'signal handler' car
ces fonctions ne sont pas atomiques, cela peut placer un <I>thread</I>
en position de <I>deadlock</I> (exclusion mutuelle avec lui-même).

<P>
Exemple :

<P>
<BR>
<PRE>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;pthread.h&gt;
#include &lt;semaphore.h&gt; 

static sem_t my_sem;
int the_end; 

void *thread1_process(void * arg)
{
   while (!the_end) {
      printf ("Je t'attend !\n");
      sem_wait (&amp;my_sem);
   }   printf ("OK, je sors !\n");
   pthread_exit (0);
   
} 
void *thread2_process(void * arg)
     {
	register int i;   for (i = 0 ; i &lt; 5 ; i++) {
	   printf ("J'arrive %d !\n", i);
	   sem_post (&amp;my_sem);
	   sleep (1);
	}   the_end = 1;
	sem_post (&amp;my_sem); /* Pour debloquer le dernier sem_wait */
	pthread_exit (0);
     } 
int main(void)
{
   pthread_t th1, th2;
   void *ret;   sem_init (&amp;my_sem, 0, 0);   
   if(pthread_create (&amp;th1, NULL, thread1_process, NULL) &lt; 0) {
      fprintf (stderr, "pthread_create error for thread 1\n");
      exit (-1);
   }   
   if(pthread_create (&amp;th2, NULL, thread2_process, NULL) &lt; 0) {
      fprintf (stderr, "pthread_create error for thread 2\n");
      exit (-1);
   } 
   (void)pthread_join (th1, &amp;ret);
   (void)pthread_join (th2, &amp;ret);

   return 0;
}
</PRE>
<P>

<H5><A NAME="SECTION00042302000000000000">
2.2.3.0.2 Exercice : Créez un programme qui simule l'exemple précédement cité
du grand magasin.</A>
</H5>

<P>
On doit simuler un magasin qui comporte 5 caisses et 20 clients voulant
payer un article (une FNAC ?).

<P>
Chaque payement prend 5 minutes (c'est une FNAC...) que l'on représentera
dans le programme par 1 seconde.

<P>
Le magasin ferme dans 15 minutes (6 secondes dans le programme), il
faut que le programme donne le nombre de clients qui auront le temps
de passer.

<P>
(Bon, c'est vrai, dans la réalité, ils feraient passer tout le monde
... mais faut bien trouver un exemple. On a qu'a dire que ce sont
des guichets SNCF)

<P>

<DL COMPACT>
<DT>
<DD>
</DD>
</DL>
<P>
</BODY>
</HTML>
